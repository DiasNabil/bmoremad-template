# BMAD+Contains Studio+MCP Alert Configuration
# Production-grade alerting rules and thresholds
# Version: 1.0.0

metadata:
  version: "1.0.0"
  description: "BMAD+Contains Studio+MCP Ecosystem Alert Rules"
  environment: "production"
  generated_by: "contains-test-performance"
  last_updated: "2025-01-08"

# Global alert settings
global:
  evaluation_interval: "30s"
  resolve_timeout: "5m"
  group_wait: "30s"
  group_interval: "5m"
  repeat_interval: "12h"

# Alert rule groups
groups:
  - name: "bmad_agent_coordination"
    interval: "30s" 
    rules:
      - alert: "AgentLatencyCritical"
        expr: 'agent_coordination_latency_ms > 3000'
        for: "2m"
        labels:
          severity: "critical"
          component: "agent"
          category: "performance"
        annotations:
          summary: "Agent coordination latency is critically high"
          description: "Agent {{ $labels.agent_name }} latency is {{ $value }}ms, exceeding critical threshold of 3000ms"
          runbook: "https://wiki.company.com/bmad/runbooks/agent-latency"
          dashboard: "https://grafana.company.com/d/bmad-agents"

      - alert: "AgentCoordinationFailureRate"
        expr: 'agent_coordination_failure_rate > 0.05'
        for: "3m"
        labels:
          severity: "critical"
          component: "agent"
          category: "reliability"
        annotations:
          summary: "Agent coordination failure rate too high"
          description: "Agent coordination failure rate is {{ $value | humanizePercentage }}, exceeding 5% threshold"

      - alert: "AgentMemoryUtilizationHigh"
        expr: 'agent_memory_utilization_percent > 80'
        for: "5m"
        labels:
          severity: "warning"
          component: "agent"
          category: "resource"
        annotations:
          summary: "Agent memory utilization high"
          description: "Agent {{ $labels.agent_name }} memory usage is {{ $value }}%, approaching critical levels"

      - alert: "ParallelExecutionEfficiencyLow"
        expr: 'parallel_execution_efficiency < 0.85'
        for: "10m"
        labels:
          severity: "warning"
          component: "coordination"
          category: "performance"
        annotations:
          summary: "Parallel execution efficiency degraded"
          description: "Parallel execution efficiency dropped to {{ $value | humanizePercentage }}"

  - name: "mcp_server_health"
    interval: "30s"
    rules:
      - alert: "MCPServerDown"
        expr: 'mcp_server_up == 0'
        for: "1m"
        labels:
          severity: "critical"
          component: "mcp"
          category: "availability"
        annotations:
          summary: "MCP Server is down"
          description: "MCP server {{ $labels.server_name }} has been down for more than 1 minute"
          runbook: "https://wiki.company.com/mcp/runbooks/server-down"
          
      - alert: "MCPResponseTimeCritical"
        expr: 'mcp_response_time_ms > 1500'
        for: "2m"
        labels:
          severity: "critical"
          component: "mcp"
          category: "performance"
        annotations:
          summary: "MCP server response time critically high"
          description: "MCP server {{ $labels.server_name }} response time is {{ $value }}ms"

      - alert: "MCPConnectionPoolExhausted"
        expr: 'mcp_connection_pool_utilization > 0.90'
        for: "3m"
        labels:
          severity: "critical"
          component: "mcp"
          category: "resource"
        annotations:
          summary: "MCP connection pool nearly exhausted"
          description: "MCP server {{ $labels.server_name }} connection pool usage at {{ $value | humanizePercentage }}"

      - alert: "MCPErrorRateHigh"
        expr: 'rate(mcp_errors_total[5m]) > 0.03'
        for: "2m"
        labels:
          severity: "warning"
          component: "mcp"
          category: "reliability"
        annotations:
          summary: "MCP server error rate elevated"
          description: "MCP server {{ $labels.server_name }} error rate: {{ $value | humanizePercentage }}"

  - name: "infrastructure_monitoring"
    interval: "30s"
    rules:
      - alert: "HighCPUUtilization"
        expr: 'cpu_utilization_percent > 85'
        for: "5m"
        labels:
          severity: "critical"
          component: "infrastructure"
          category: "resource"
        annotations:
          summary: "High CPU utilization detected"
          description: "CPU utilization is {{ $value }}% on {{ $labels.instance }}"

      - alert: "HighMemoryUtilization"
        expr: 'memory_utilization_percent > 80'
        for: "5m"
        labels:
          severity: "critical"
          component: "infrastructure"
          category: "resource"
        annotations:
          summary: "High memory utilization detected"
          description: "Memory utilization is {{ $value }}% on {{ $labels.instance }}"

      - alert: "DiskSpaceLow"
        expr: 'disk_utilization_percent > 90'
        for: "2m"
        labels:
          severity: "critical"
          component: "infrastructure"
          category: "resource"
        annotations:
          summary: "Disk space critically low"
          description: "Disk usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: "NetworkLatencyHigh"
        expr: 'network_latency_ms > 200'
        for: "3m"
        labels:
          severity: "warning"
          component: "infrastructure"
          category: "network"
        annotations:
          summary: "Network latency elevated"
          description: "Network latency is {{ $value }}ms to {{ $labels.destination }}"

  - name: "security_monitoring"
    interval: "60s"
    rules:
      - alert: "SecurityViolationDetected"
        expr: 'security_violations_total > 0'
        for: "0s"
        labels:
          severity: "critical"
          component: "security"
          category: "compliance"
        annotations:
          summary: "Security violation detected"
          description: "{{ $value }} security violation(s) detected in the last minute"
          runbook: "https://wiki.company.com/security/incident-response"

      - alert: "AuthenticationFailureSpike"
        expr: 'rate(authentication_failures_total[5m]) > 10'
        for: "2m"
        labels:
          severity: "warning"
          component: "security"
          category: "access_control"
        annotations:
          summary: "Authentication failure spike detected"
          description: "{{ $value }} authentication failures per second over last 5 minutes"

      - alert: "ComplianceScoreBelowThreshold"
        expr: 'compliance_score_percent < 98'
        for: "5m"
        labels:
          severity: "warning"
          component: "security"
          category: "compliance"
        annotations:
          summary: "Compliance score below acceptable threshold"
          description: "Compliance score dropped to {{ $value }}%"

  - name: "business_metrics"
    interval: "300s"
    rules:
      - alert: "SystemUptimeBelowSLA"
        expr: 'system_uptime_percent < 99.9'
        for: "1m"
        labels:
          severity: "critical"
          component: "business"
          category: "sla"
        annotations:
          summary: "System uptime below SLA"
          description: "System uptime {{ $value }}% is below 99.9% SLA requirement"

      - alert: "UserSatisfactionLow"
        expr: 'user_satisfaction_score < 4.0'
        for: "10m"
        labels:
          severity: "warning"
          component: "business"
          category: "user_experience"
        annotations:
          summary: "User satisfaction score declining"
          description: "User satisfaction score is {{ $value }}/5.0"

      - alert: "TransactionThroughputLow"
        expr: 'transaction_throughput_per_second < 50'
        for: "5m"
        labels:
          severity: "warning"
          component: "business"
          category: "performance"
        annotations:
          summary: "Transaction throughput below expected levels"
          description: "Current throughput: {{ $value }} transactions/second"

# Predictive alerts
  - name: "predictive_alerts"
    interval: "300s"
    rules:
      - alert: "PredictedCapacityIssue"
        expr: 'predict_linear(resource_utilization_percent[30m], 3600) > 95'
        for: "10m"
        labels:
          severity: "warning"
          component: "predictive"
          category: "capacity"
        annotations:
          summary: "Predicted capacity issue in next hour"
          description: "Resource utilization predicted to exceed 95% within 1 hour"

      - alert: "PredictedPerformanceDegradation"
        expr: 'predict_linear(response_time_ms[30m], 1800) > 5000'
        for: "5m"
        labels:
          severity: "warning"
          component: "predictive"
          category: "performance"
        annotations:
          summary: "Performance degradation predicted"
          description: "Response time predicted to exceed 5000ms within 30 minutes"

# Alert routing and notification rules
route:
  group_by: ["alertname", "component", "severity"]
  group_wait: "30s"
  group_interval: "5m"
  repeat_interval: "12h"
  receiver: "default-receiver"
  
  routes:
    # Critical alerts get immediate notification
    - match:
        severity: "critical"
      receiver: "critical-alerts"
      group_wait: "5s"
      repeat_interval: "5m"
      
    # Security alerts have special routing
    - match:
        component: "security"
      receiver: "security-team"
      group_wait: "0s"
      
    # Business metric alerts go to executives
    - match:
        component: "business"
      receiver: "business-stakeholders"
      group_interval: "10m"

# Notification receivers
receivers:
  - name: "default-receiver"
    slack_configs:
      - api_url: "${SLACK_WEBHOOK_URL}"
        channel: "#bmad-alerts"
        title: "BMAD Alert - {{ .GroupLabels.alertname }}"
        text: "{{ .CommonAnnotations.summary }}\n{{ .CommonAnnotations.description }}"
        
  - name: "critical-alerts"
    slack_configs:
      - api_url: "${SLACK_WEBHOOK_URL}"
        channel: "#bmad-critical"
        title: "🚨 CRITICAL: {{ .GroupLabels.alertname }}"
        text: "{{ .CommonAnnotations.summary }}\n{{ .CommonAnnotations.description }}"
        color: "danger"
    email_configs:
      - to: "${CRITICAL_ALERT_EMAILS}"
        from: "${ALERT_FROM_EMAIL}"
        subject: "🚨 BMAD Critical Alert: {{ .GroupLabels.alertname }}"
        body: |
          Critical alert detected in BMAD ecosystem.
          
          Alert: {{ .GroupLabels.alertname }}
          Severity: {{ .GroupLabels.severity }}
          Component: {{ .GroupLabels.component }}
          
          {{ .CommonAnnotations.description }}
          
          Time: {{ .CommonAnnotations.timestamp }}
          
          Please investigate immediately.
          
  - name: "security-team"
    slack_configs:
      - api_url: "${SLACK_WEBHOOK_URL}"
        channel: "#security-alerts"
        title: "🔒 Security Alert: {{ .GroupLabels.alertname }}"
        text: "{{ .CommonAnnotations.summary }}\n{{ .CommonAnnotations.description }}"
        color: "#ff4444"
    email_configs:
      - to: "${SECURITY_TEAM_EMAILS}"
        from: "${ALERT_FROM_EMAIL}"
        subject: "🔒 BMAD Security Alert: {{ .GroupLabels.alertname }}"
        
  - name: "business-stakeholders"
    email_configs:
      - to: "${BUSINESS_STAKEHOLDER_EMAILS}"
        from: "${ALERT_FROM_EMAIL}"
        subject: "📊 BMAD Business Metric Alert: {{ .GroupLabels.alertname }}"

# Alert inhibition rules
inhibit_rules:
  # Don't alert on individual agents if overall coordination is down
  - source_match:
      alertname: "AgentCoordinationFailureRate"
    target_match:
      component: "agent"
    equal: ["component"]
    
  # Don't alert on MCP response time if server is down
  - source_match:
      alertname: "MCPServerDown"
    target_match:
      alertname: "MCPResponseTimeCritical"
    equal: ["server_name"]

# Silence rules for maintenance windows
silences:
  - matchers:
      - name: "maintenance_window"
        value: "true"
    comment: "Maintenance window - alerts suppressed"
    created_by: "bmad-devops"

# Custom alert labels and annotations
custom_labels:
  team: "bmad-platform"
  environment: "production"
  ecosystem: "bmad-contains-mcp"
  monitoring_version: "1.0.0"
  
custom_annotations:
  wiki_base_url: "https://wiki.company.com/bmad"
  dashboard_base_url: "https://grafana.company.com/d"
  incident_management: "https://pagerduty.com/incidents"